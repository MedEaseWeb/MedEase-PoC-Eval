{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simplification_pipeline.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment='Simplification Pipeline Graph (No Dynamic Layer)', format='png')\n",
    "dot.attr(rankdir='LR', fontname=\"LibreSans\")  # Left to right layout\n",
    "\n",
    "# Input and Output\n",
    "dot.node('Input', 'Input\\n(Medical Report)', shape='oval')\n",
    "dot.node('Output', 'Output\\n(Simplified Report)', shape='oval')\n",
    "\n",
    "# Define models\n",
    "lexical_models = {\n",
    "    # \"L1\": \"gpt-o1\",   # gpt-o1 got high-precision benchmarking and clinical release-ready output, but it's way more expensive \n",
    "    \"L2\": \"gpt-4o\", # comparing to o1, gives around ~95% of the quality at ~17% of the cost\n",
    "    \"L3\": \"deepseek-chat\",\n",
    "    \"L4\": \"MedLlama\"\n",
    "}\n",
    "\n",
    "syntactic_models = {\n",
    "    \"S1\": \"gpt-4o\",\n",
    "    # \"S2\": \"gpt-4o-mini\",  # cost lower than 4o, perform a little bit worse. same tier as ds chat.\n",
    "    \"S3\": \"deepseek-chat\",\n",
    "    \"S4\": \"t5-small\",\n",
    "    \"S5\": \"bart-large-cnn\",\n",
    "    \"S6\": \"MedLlama\"\n",
    "}\n",
    "\n",
    "format_models = {\n",
    "    \"F1\": \"gpt-4o-mini\",\n",
    "    \"F2\": \"t5-small\",\n",
    "    \"F3\": \"bart-large-cnn\",\n",
    "    \"F4\": \"deepseek-chat\",\n",
    "    \"F5\": \"MedLlama\"\n",
    "}\n",
    "\n",
    "# Create same-rank subgraphs to align vertically\n",
    "with dot.subgraph() as s:\n",
    "    s.attr(rank='same')\n",
    "    for key, label in lexical_models.items():\n",
    "        s.node(key, f\"Lexical\\n({label})\")\n",
    "\n",
    "with dot.subgraph() as s:\n",
    "    s.attr(rank='same')\n",
    "    for key, label in syntactic_models.items():\n",
    "        s.node(key, f\"Syntactic\\n({label})\")\n",
    "\n",
    "with dot.subgraph() as s:\n",
    "    s.attr(rank='same')\n",
    "    for key, label in format_models.items():\n",
    "        s.node(key, f\"Format\\n({label})\")\n",
    "\n",
    "# Connections\n",
    "for key in lexical_models.keys():\n",
    "    dot.edge('Input', key)\n",
    "\n",
    "for l_key in lexical_models.keys():\n",
    "    for s_key in syntactic_models.keys():\n",
    "        dot.edge(l_key, s_key)\n",
    "\n",
    "for s_key in syntactic_models.keys():\n",
    "    for f_key in format_models.keys():\n",
    "        dot.edge(s_key, f_key)\n",
    "\n",
    "for f_key in format_models.keys():\n",
    "    dot.edge(f_key, 'Output')\n",
    "\n",
    "# Output the diagram\n",
    "dot.render('simplification_pipeline', format='png', cleanup=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
