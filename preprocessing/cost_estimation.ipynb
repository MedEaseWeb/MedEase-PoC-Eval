{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348.192\n",
      "209.778\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"./500_pairs.json\")\n",
    "\n",
    "'''\n",
    "    Get average token count for both target and source.\n",
    "'''\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split(\" \")\n",
    "\n",
    "# print(df[\"source\"][0])\n",
    "\n",
    "tkn_len_src = 0\n",
    "tkn_len_trg = 0\n",
    "\n",
    "for source_report in df[\"source\"]:\n",
    "    tkn_len_src += len(tokenize(source_report))\n",
    "    \n",
    "for target_report in df[\"target\"]:\n",
    "    tkn_len_trg += len(tokenize(target_report))\n",
    "    \n",
    "tkn_len_src /= 500\n",
    "tkn_len_trg /= 500\n",
    "\n",
    "print(tkn_len_src)\n",
    "print(tkn_len_trg)\n",
    "\n",
    "total_reports = 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price menu: \n",
    "pricing = {\n",
    "    \"gpt-4o (api)\": {\"input\":2.50, \"output\": 10},\n",
    "    \"gpt-4o-mini (api)\": {\"input\":0.15, \"output\": 0.6},\n",
    "    # \"deepseek-chat (api)\": {\"input\":0.135, \"output\": 0.55},   # discount hour, cache miss\n",
    "    \"deepseek-chat (api)\": {\"input\":0.27, \"output\": 1.10},   # non-discount hour, cache miss\n",
    "    \"t5-small (local)\": {\"input\":0, \"output\": 0},\n",
    "    \"bart-large-cnn (local)\":  {\"input\":0, \"output\": 0},\n",
    "    \"MedLlama-3-8B-v2.0 (local)\": {\"input\":0, \"output\":0}\n",
    "}\n",
    "\n",
    "# https://platform.openai.com/docs/pricing\n",
    "# https://api-docs.deepseek.com/quick_start/pricing\n",
    "# https://huggingface.co/johnsnowlabs/JSL-MedLlama-3-8B-v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL COST ESTIMATION (Layered Tree Execution) ===\n",
      "\n",
      "--- Lexical Layer ---\n",
      "gpt-4o (api)              | Calls: 500   | Cost: $1.4841\n",
      "deepseek-chat (api)       | Calls: 500   | Cost: $0.1624\n",
      "MedLlama-3-8B-v2.0 (local) | Calls: 500   | Cost: $0.0000\n",
      "\n",
      "--- Syntactic Layer ---\n",
      "gpt-4o (api)              | Calls: 1500  | Cost: $4.4524\n",
      "deepseek-chat (api)       | Calls: 1500  | Cost: $0.4872\n",
      "t5-small (local)          | Calls: 1500  | Cost: $0.0000\n",
      "bart-large-cnn (local)    | Calls: 1500  | Cost: $0.0000\n",
      "MedLlama-3-8B-v2.0 (local) | Calls: 1500  | Cost: $0.0000\n",
      "\n",
      "--- Format Layer ---\n",
      "gpt-4o-mini (api)         | Calls: 7500  | Cost: $1.3357\n",
      "t5-small (local)          | Calls: 7500  | Cost: $0.0000\n",
      "bart-large-cnn (local)    | Calls: 7500  | Cost: $0.0000\n",
      "deepseek-chat (api)       | Calls: 7500  | Cost: $2.4358\n",
      "MedLlama-3-8B-v2.0 (local) | Calls: 7500  | Cost: $0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selected Models\n",
    "lexical_models = {\n",
    "    \"L2\": \"gpt-4o (api)\",\n",
    "    \"L3\": \"deepseek-chat (api)\",\n",
    "    \"L4\": \"MedLlama-3-8B-v2.0 (local)\"\n",
    "}\n",
    "syntactic_models = {\n",
    "    \"S1\": \"gpt-4o (api)\",\n",
    "    \"S3\": \"deepseek-chat (api)\",\n",
    "    \"S4\": \"t5-small (local)\",\n",
    "    \"S5\": \"bart-large-cnn (local)\",\n",
    "    \"S6\": \"MedLlama-3-8B-v2.0 (local)\"\n",
    "}\n",
    "format_models = {\n",
    "    \"F1\": \"gpt-4o-mini (api)\",\n",
    "    \"F2\": \"t5-small (local)\",\n",
    "    \"F3\": \"bart-large-cnn (local)\",\n",
    "    \"F4\": \"deepseek-chat (api)\",\n",
    "    \"F5\": \"MedLlama-3-8B-v2.0 (local)\"\n",
    "}\n",
    "\n",
    "# Token stats (replace with real averages)\n",
    "avg_input_tokens = tkn_len_src\n",
    "avg_output_tokens = tkn_len_trg\n",
    "N = 500  # reports\n",
    "\n",
    "# Fan-out call multipliers\n",
    "calls_per_model = {\n",
    "    \"Lexical\": N,\n",
    "    \"Syntactic\": N * len(lexical_models),\n",
    "    \"Format\": N * len(lexical_models) * len(syntactic_models)\n",
    "}\n",
    "\n",
    "# Models grouped by layer\n",
    "models_by_layer = {\n",
    "    \"Lexical\": lexical_models,\n",
    "    \"Syntactic\": syntactic_models,\n",
    "    \"Format\": format_models\n",
    "}\n",
    "\n",
    "# Calculate cost\n",
    "print(\"=== FINAL COST ESTIMATION (Layered Tree Execution) ===\\n\")\n",
    "\n",
    "for layer, models in models_by_layer.items():\n",
    "    print(f\"--- {layer} Layer ---\")\n",
    "    call_count = calls_per_model[layer]\n",
    "    \n",
    "    for model_id, model_name in models.items():\n",
    "        cost_in = (avg_input_tokens * call_count / 1_000_000) * pricing[model_name][\"input\"]\n",
    "        cost_out = (avg_output_tokens * call_count / 1_000_000) * pricing[model_name][\"output\"]\n",
    "        total_cost = cost_in + cost_out\n",
    "        \n",
    "        print(f\"{model_name.ljust(25)} | Calls: {call_count:<5} | Cost: ${total_cost:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.3576"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost = 1.4841 + 0.1624 + 4.4524 + 0.4872 + 1.3357 + 2.4358\n",
    "total_cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
